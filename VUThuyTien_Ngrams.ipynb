{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n34c7RAI2ruj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec819b6-fae4-45ba-ce4c-d44ed92b88c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install & import\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "\n",
        "# Step 2: Load and clean the corpus\n",
        "tokenized_text = brown.words()\n",
        "tokenized_text = [word.lower() for word in tokenized_text if word.isalpha()]  # remove punctuation/numbers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define function to build n-gram DataFrame\n",
        "def generate_ngram_df(tokens, n):\n",
        "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
        "    ngram_list = [' '.join(gram) for gram in ngrams]\n",
        "    freq = Counter(ngram_list)\n",
        "    df = pd.DataFrame(freq.items(), columns=['ngram', 'frequency']).sort_values(by='frequency', ascending=False)\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "# Example usage: trigram frequencies\n",
        "trigrams_df = generate_ngram_df(tokenized_text, 3)\n",
        "print(trigrams_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4_MF2m3vNo",
        "outputId": "2f6d2d01-bdef-4f14-949e-ed0a923755a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               ngram  frequency\n",
            "0         one of the        404\n",
            "1  the united states        337\n",
            "2         as well as        238\n",
            "3        some of the        179\n",
            "4         out of the        174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Predict top k next words based on n-grams\n",
        "def predict_next_words(tokens, n, k=5):\n",
        "    \"\"\"tokens: list of words (or a string)\n",
        "       n: n-gram size\n",
        "       k: number of suggestions\"\"\"\n",
        "\n",
        "    if isinstance(tokens, str):\n",
        "        tokens = tokens.lower().split()\n",
        "\n",
        "    if len(tokens) < n - 1:\n",
        "        raise ValueError(f\"You must provide at least {n-1} word(s) for a {n}-gram model.\")\n",
        "\n",
        "    context = ' '.join(tokens[-(n-1):])\n",
        "\n",
        "    # Generate all n-grams\n",
        "    ngrams = zip(*[tokenized_text[i:] for i in range(n)])\n",
        "    ngram_strings = [' '.join(ng) for ng in ngrams]\n",
        "\n",
        "    # Filter n-grams that match the context\n",
        "    matching = [ngram for ngram in ngram_strings if ngram.startswith(context + ' ')]\n",
        "    next_words = [ngram.split()[-1] for ngram in matching]\n",
        "\n",
        "    top_k = Counter(next_words).most_common(k)\n",
        "    return pd.DataFrame(top_k, columns=['next_word', 'frequency'])\n",
        "\n",
        "# Example usage\n",
        "print(\"\\nPredictions for context: 'the united'\")\n",
        "print(predict_next_words(\"the united\", n=3, k=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsPSWadz3zeO",
        "outputId": "16f7d405-815b-48bf-92ff-60cdc43d98d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions for context: 'the united'\n",
            "   next_word  frequency\n",
            "0     states        337\n",
            "1    nations         42\n",
            "2   profound          1\n",
            "3      irish          1\n",
            "4  challenge          1\n"
          ]
        }
      ]
    }
  ]
}